{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d882cc-eb35-41ba-9f5e-63503abe4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0463d32-aada-4812-9967-dd2413bba156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# call the flow from directory method on it to get it to load images from that directory \n",
    "# and its sub-directories. name of the sub-direcotries will be the labels for your images \n",
    "# that are contained within them. \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,                    # the directory you're pointing to\n",
    "    target_size=(300, 300),       # images are resized as they are loaded\n",
    "    batch_size=128\n",
    "    class_mode='binary')          #  i.e. it picks between two different things; horses and humans,\n",
    "# It's a common mistake that people point the generator at the sub-directory. It will fail in that \n",
    "# circumstance. You should always point it at the directory that contains sub-directories that \n",
    "#contain your images. \n",
    "\n",
    "# Now, images might come in all shapes and sizes and unfortunately for training a neural network, \n",
    "# the input data all has to be the same size, so the images will need to be resized to make them \n",
    "# consistent. The nice thing about this code is that the images are resized for you as \n",
    "# they're loaded. So you don't need to preprocess thousands of images on your file system.\n",
    "\n",
    "# Finally, there's the class mode. Now, this is a binary classifier i.e. it picks between two \n",
    "\n",
    "# different things; horses and humans, \n",
    "\n",
    "# the validation generator should be exactly the same except of course it points at a different\n",
    "# directory, the one containing the sub-directories containing the test images.\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,                   \n",
    "    target_size=(300, 300),      \n",
    "    batch_size=128\n",
    "    class_mode='binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8476a47b-5c8d-41c6-90c1-808605ac466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 06:06:22.549011: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-21 06:06:22.549156: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # 300x300 size, 3 = RGB colors\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # one neuron two classes bcs of the different actiavtion function\n",
    "    # where sigmoid is great for binary classification, where one class will tend \n",
    "    # towards zero and the other class tending towards one.\n",
    "    # You could use two neurons here if you want, and the same softmax function as before, \n",
    "    # but for binary this is a bit more efficient.\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5fe883-c8ab-434b-a1ac-5fef21396fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 78400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               40141312  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,165,409\n",
      "Trainable params: 40,165,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2542ec-75b5-44c0-9ddc-1f0a92bd0397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonggihkang/miniforge3/envs/TF/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',       # binary choice so binary crossentropy\n",
    "              optimizer=RMSprop(lr=0.001),      # earlier we used an Adam optimizer. Now, you could do that again, \n",
    "                                                # but I thought it would be fun to use the RMSprop, where you can adjust the learning rate to experiment with performance. \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99967d2-f530-4ac0-9d49-b166fae98d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(     # not model.fit because now we are using a generator instead of datasets\n",
    "    train_generator,               # This streams the images from the training directory.\n",
    "    steps_per_epoch=8,             # Remember the batch size you used when you created it, it was 20, \n",
    "                                   # that's important in the next step. There are 1,024 images in the training directory, \n",
    "                                   # so we're loading them in 128 at a time. So in order to load them all, we need to do 8 batches.\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=8,            # It had 256 images, and we wanted to handle them in batches of 32, so we will do 8 steps.\n",
    "    verbose=2)                     # And the verbose parameter specifies how much to display while training is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c67235-4ced-4197-98c2-13fc32fdf255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    \n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path, target_size=(300, 300))  #\n",
    "    x = image.img_to_array(img)                         # you can load an image and prepare it to \n",
    "    x = np.expand_dims(x, axis=0)                       # input into the model with this code. \n",
    "    images = np.vstack([x])                             # N.B. match the input dimensions that you \n",
    "                                                        # specified when designing the model. \n",
    "    \n",
    "    classes = model.predict(images, batch_size=10)      # You can then call model.predict, passing it \n",
    "                                                        # the details, and it will return an array of classes. \n",
    "    print(classes[0])\n",
    "    # In the case of binary classification, this will only contain one item with a \n",
    "    # value close to 0 for one class and close to 1 for the other.\n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a human\")\n",
    "    else:\n",
    "        print(fn \" is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36bf88-6e4b-4fae-80e0-34f7c6856703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407906d7-8e9d-498b-adc8-45ee4d185279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cd80a-93be-4c4f-95e9-6faff0da2d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
